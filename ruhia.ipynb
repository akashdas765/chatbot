{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rT7-eh4HxFj3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import string\n",
    "import re\n",
    "import joblib\n",
    "import json\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import bert\n",
    "from bert import BertModelLayer\n",
    "from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\n",
    "from bert.tokenization.bert_tokenization import FullTokenizer\n",
    " \n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, Flatten\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sHSn7tNgxH5H"
   },
   "outputs": [],
   "source": [
    "main_path=\"C:/Users/akash/Desktop/UI/Chatbot/\"\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('C:/Users/akash/Desktop/UI/saved_models/rmsmodel3.h5', custom_objects={\"BertModelLayer\": bert.BertModelLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ecTfF_apgmeK"
   },
   "outputs": [],
   "source": [
    "bert_model_name=\"uncased_L-12_H-768_A-12\"\n",
    " \n",
    "#bert_ckpt_dir = os.path.join(\"model/\", bert_model_name)\n",
    "bert_ckpt_file = os.path.join(main_path,\"bert_model.ckpt.index\")\n",
    "bert_config_file = os.path.join(main_path,\"bert_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "w0nfp0gKjYcR"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(main_path+\"newtrain.csv\")\n",
    "#valid = pd.read_csv(\"valid.csv\")\n",
    "test = pd.read_csv(main_path+\"newtrain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-hQMjo_jhSr9"
   },
   "outputs": [],
   "source": [
    "class IntentDetectionData:\n",
    "  DATA_COLUMN = \"questions\"\n",
    "  LABEL_COLUMN = \"labels\"\n",
    " \n",
    "  def __init__(self, train, test, tokenizer: FullTokenizer, classes, max_seq_len=192):\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_seq_len = 0\n",
    "    self.classes = classes\n",
    "    \n",
    "    ((self.train_x, self.train_y), (self.test_x, self.test_y)) = map(self._prepare, [train, test])\n",
    " \n",
    "    print(\"max seq_len\", self.max_seq_len)\n",
    "    self.max_seq_len = min(self.max_seq_len, max_seq_len)\n",
    "    self.train_x, self.test_x = map(self._pad, [self.train_x, self.test_x])\n",
    " \n",
    "  def _prepare(self, df):\n",
    "    x, y = [], []\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows()):\n",
    "      text, label = row[IntentDetectionData.DATA_COLUMN], row[IntentDetectionData.LABEL_COLUMN]\n",
    "      tokens = self.tokenizer.tokenize(text)\n",
    "      tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
    "      token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "      self.max_seq_len = max(self.max_seq_len, len(token_ids))\n",
    "      x.append(token_ids)\n",
    "      y.append(self.classes.index(label))\n",
    " \n",
    "    return np.array(x), np.array(y)\n",
    " \n",
    "  def _pad(self, ids):\n",
    "    x = []\n",
    "    for input_ids in ids:\n",
    "      input_ids = input_ids[:min(len(input_ids), self.max_seq_len - 2)]\n",
    "      input_ids = input_ids + [0] * (self.max_seq_len - len(input_ids))\n",
    "      x.append(np.array(input_ids))\n",
    "    return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vs7XYMWVhXXl"
   },
   "outputs": [],
   "source": [
    "tokenizer = FullTokenizer(vocab_file=os.path.join(main_path+\"uncased_L-12_H-768_A-12/vocab.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2705,
     "status": "ok",
     "timestamp": 1611752265508,
     "user": {
      "displayName": "Akash Das",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjOjhArzumpHzN1_p3oinNftWxwSl7K3ieh0roeTiY=s64",
      "userId": "00521560618217958862"
     },
     "user_tz": -330
    },
    "id": "OqP6IDD_jTPW",
    "outputId": "b10f8255-080d-4b8f-def5-30977009acb6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "198it [00:00, 1147.94it/s]\n",
      "C:\\Users\\akash\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "198it [00:00, 1711.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max seq_len 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classes = train.labels.unique().tolist()\n",
    " \n",
    "data = IntentDetectionData(train, test, tokenizer, classes, max_seq_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oIFYksNZweZQ"
   },
   "outputs": [],
   "source": [
    "# import our chat-bot intents file\n",
    "import json\n",
    "with open(main_path+'newintents2.json') as json_data:\n",
    "    intents = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# create a data structure to hold user context\n",
    "context = {}\n",
    " \n",
    " \n",
    "ERROR_THRESHOLD = 0.25\n",
    "def classify(sentence):\n",
    "    sentence=[sentence]\n",
    "    pred_tokens = map(tokenizer.tokenize, sentence)\n",
    "    pred_tokens = map(lambda tok: [\"[CLS]\"] + tok + [\"[SEP]\"], pred_tokens)\n",
    "    pred_token_ids = list(map(tokenizer.convert_tokens_to_ids, pred_tokens))\n",
    " \n",
    "    pred_token_ids = map(lambda tids: tids +[0]*(data.max_seq_len-len(tids)),pred_token_ids)\n",
    "    pred_token_ids = np.array(list(pred_token_ids))\n",
    " \n",
    "    predictions = model.predict(pred_token_ids)\n",
    "    predictions1=np.argmax(model.predict(pred_token_ids))\n",
    "    \n",
    "    return_list =[]\n",
    "    return_list.append((classes[predictions1],np.amax(predictions[0])))\n",
    "    \n",
    "    return return_list\n",
    " \n",
    " \n",
    "def response(sentence, userID='123', show_details=False):\n",
    "    results = classify(sentence)\n",
    "    but=[]\n",
    "    # if we have a classification then find the matching intent tag\n",
    "    if results:\n",
    "        # loop as long as there are matches to process\n",
    "        while results:\n",
    "            for i in intents['intents']:\n",
    "                # find a tag matching the first result\n",
    "                if i['tag'] == results[0][0]:\n",
    "                    x=i['id']\n",
    "                    but=i['buttons']\n",
    "                    # set context for this intent if necessary\n",
    "                    if 'context_set' in i:\n",
    "                        if show_details: \n",
    "                            return (('context:', i['context_set']),x,but)\n",
    "                        context[userID] = i['context_set']\n",
    " \n",
    "                    # check if this intent is contextual and applies to this user's conversation\n",
    "                    if not 'context_filter' in i or \\\n",
    "                        (userID in context and 'context_filter' in i and i['context_filter'] == context[userID]):\n",
    "                        if show_details: print ('tag:', i['tag'])\n",
    "                        # a random response from the intent\n",
    "                        return (random.choice(i['responses']),x,but)\n",
    "    \n",
    "            results.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4664,
     "status": "ok",
     "timestamp": 1611752304804,
     "user": {
      "displayName": "Akash Das",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjOjhArzumpHzN1_p3oinNftWxwSl7K3ieh0roeTiY=s64",
      "userId": "00521560618217958862"
     },
     "user_tz": -330
    },
    "id": "jwZTeld8s5To",
    "outputId": "00ab0a65-d560-44b8-c398-72e81f7edc08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bvoc_dep_sen', 0.99999976)] ('We offer the following departments to our senior students. Please choose by clicking on one of the buttons', 27, ['Green House Management', 'Pharma Analytical Sciences', 'Tourism Travel Management'])\n"
     ]
    }
   ],
   "source": [
    "sent=\"centers\"\n",
    "print(classify(sent),response(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [23/Feb/2021 18:48:13] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [23/Feb/2021 18:48:16] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what can you do?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Feb/2021 18:48:24] \"\u001b[37mGET /get?msg=what%20can%20you%20do%3F HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About Ruhia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Feb/2021 18:48:26] \"\u001b[37mGET /get?msg=About%20Ruhia HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruhia Junior College\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Feb/2021 18:48:28] \"\u001b[37mGET /get?msg=Ruhia%20Junior%20College HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruhia Senior college\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Feb/2021 18:48:32] \"\u001b[37mGET /get?msg=Ruhia%20Senior%20college HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Feb/2021 18:48:34] \"\u001b[37mGET /get?msg=Academics HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examination\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-23 18:48:39,681] ERROR in app: Exception on /get [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\akash\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 2446, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\akash\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1951, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\akash\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1820, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\akash\\anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\akash\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1949, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\akash\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1935, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-11-569ea3565053>\", line 16, in get_bot_response\n",
      "    res,x,buttons=response(message)\n",
      "TypeError: cannot unpack non-iterable NoneType object\n",
      "127.0.0.1 - - [23/Feb/2021 18:48:39] \"\u001b[35m\u001b[1mGET /get?msg=Examination HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centers/Cells\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Feb/2021 18:48:44] \"\u001b[37mGET /get?msg=Centers%2FCells HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facilities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Feb/2021 18:48:51] \"\u001b[37mGET /get?msg=Facilities HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [23/Feb/2021 18:49:13] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what can you do?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Feb/2021 18:49:20] \"\u001b[37mGET /get?msg=what%20can%20you%20do%3F HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About Ruhia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Feb/2021 18:49:23] \"\u001b[37mGET /get?msg=About%20Ruhia HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruhia Junior College\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Feb/2021 18:49:25] \"\u001b[37mGET /get?msg=Ruhia%20Junior%20College HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examination\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Feb/2021 18:49:27] \"\u001b[37mGET /get?msg=Examination HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Feb/2021 18:49:30] \"\u001b[37mGET /get?msg=Results HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Programmes-Subjects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Feb/2021 18:49:33] \"\u001b[37mGET /get?msg=Programmes-Subjects HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contact details\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Feb/2021 18:56:51] \"\u001b[37mGET /get?msg=Contact%20details HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whatsapp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Feb/2021 18:56:53] \"\u001b[37mGET /get?msg=Whatsapp HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Feb/2021 18:56:55] \"\u001b[37mGET /get?msg=Phone HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Feb/2021 18:56:57] \"\u001b[37mGET /get?msg=Email HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request, jsonify\n",
    "#from flask_ngrok import run_with_ngrok\n",
    "app = Flask(__name__, template_folder=main_path+'templates/UI')\n",
    "#run_with_ngrok(app)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index3.html')\n",
    "\n",
    "@app.route('/get')\n",
    "def get_bot_response():\n",
    "    message = request.args.get('msg')\n",
    "    print(message)\n",
    "    if message:\n",
    "        message = message.lower()\n",
    "        res,x,buttons=response(message)\n",
    "        mess = {'response':res,'id':x,'buttons':buttons}\n",
    "        return jsonify(mess)\n",
    "    return \"Missing Data!\"\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOEbOB9guBy0v7uPsykyBot",
   "collapsed_sections": [],
   "name": "Copy of Implement.ipynb",
   "provenance": [
    {
     "file_id": "1KLpXslUuTwj_2J3ofQbJD8ZPeCB3B24n",
     "timestamp": 1611832601184
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
