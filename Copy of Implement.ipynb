{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8249,
     "status": "ok",
     "timestamp": 1611752201176,
     "user": {
      "displayName": "Akash Das",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjOjhArzumpHzN1_p3oinNftWxwSl7K3ieh0roeTiY=s64",
      "userId": "00521560618217958862"
     },
     "user_tz": -330
    },
    "id": "-BxslStexg4K",
    "outputId": "4639f3a0-f781-4ed9-a64f-139cbff90ad4"
   },
   "outputs": [],
   "source": [
    "!pip install bert-for-tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11011,
     "status": "ok",
     "timestamp": 1611752203949,
     "user": {
      "displayName": "Akash Das",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjOjhArzumpHzN1_p3oinNftWxwSl7K3ieh0roeTiY=s64",
      "userId": "00521560618217958862"
     },
     "user_tz": -330
    },
    "id": "tYc9XSI74u4C",
    "outputId": "9012fe58-4338-4924-87e5-ca790e2fe664"
   },
   "outputs": [],
   "source": [
    "!pip install flask-ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rT7-eh4HxFj3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import string\n",
    "import re\n",
    "import joblib\n",
    "import json\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import bert\n",
    "from bert import BertModelLayer\n",
    "from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\n",
    "from bert.tokenization.bert_tokenization import FullTokenizer\n",
    " \n",
    " \n",
    " \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, Flatten\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sHSn7tNgxH5H"
   },
   "outputs": [],
   "source": [
    "main_path=\"C:/Users/akash/Desktop/UI/Chatbot/\"\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(main_path+'saved_models/model.h5', custom_objects={\"BertModelLayer\": bert.BertModelLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ecTfF_apgmeK"
   },
   "outputs": [],
   "source": [
    "bert_model_name=\"uncased_L-12_H-768_A-12\"\n",
    " \n",
    "#bert_ckpt_dir = os.path.join(\"model/\", bert_model_name)\n",
    "bert_ckpt_file = os.path.join(main_path,\"bert_model.ckpt.index\")\n",
    "bert_config_file = os.path.join(main_path,\"bert_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w0nfp0gKjYcR"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(main_path+\"train.csv\")\n",
    "#valid = pd.read_csv(\"valid.csv\")\n",
    "test = pd.read_csv(main_path+\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-hQMjo_jhSr9"
   },
   "outputs": [],
   "source": [
    "class IntentDetectionData:\n",
    "  DATA_COLUMN = \"questions\"\n",
    "  LABEL_COLUMN = \"labels\"\n",
    " \n",
    "  def __init__(self, train, test, tokenizer: FullTokenizer, classes, max_seq_len=192):\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_seq_len = 0\n",
    "    self.classes = classes\n",
    "    \n",
    "    ((self.train_x, self.train_y), (self.test_x, self.test_y)) = map(self._prepare, [train, test])\n",
    " \n",
    "    print(\"max seq_len\", self.max_seq_len)\n",
    "    self.max_seq_len = min(self.max_seq_len, max_seq_len)\n",
    "    self.train_x, self.test_x = map(self._pad, [self.train_x, self.test_x])\n",
    " \n",
    "  def _prepare(self, df):\n",
    "    x, y = [], []\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows()):\n",
    "      text, label = row[IntentDetectionData.DATA_COLUMN], row[IntentDetectionData.LABEL_COLUMN]\n",
    "      tokens = self.tokenizer.tokenize(text)\n",
    "      tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
    "      token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "      self.max_seq_len = max(self.max_seq_len, len(token_ids))\n",
    "      x.append(token_ids)\n",
    "      y.append(self.classes.index(label))\n",
    " \n",
    "    return np.array(x), np.array(y)\n",
    " \n",
    "  def _pad(self, ids):\n",
    "    x = []\n",
    "    for input_ids in ids:\n",
    "      input_ids = input_ids[:min(len(input_ids), self.max_seq_len - 2)]\n",
    "      input_ids = input_ids + [0] * (self.max_seq_len - len(input_ids))\n",
    "      x.append(np.array(input_ids))\n",
    "    return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vs7XYMWVhXXl"
   },
   "outputs": [],
   "source": [
    "tokenizer = FullTokenizer(vocab_file=os.path.join(main_path+\"uncased_L-12_H-768_A-12/vocab.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 62639,
     "status": "ok",
     "timestamp": 1611120259743,
     "user": {
      "displayName": "Akash Das",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjOjhArzumpHzN1_p3oinNftWxwSl7K3ieh0roeTiY=s64",
      "userId": "00521560618217958862"
     },
     "user_tz": -330
    },
    "id": "6Vsloit7jEXd",
    "outputId": "2eb3cf6a-7b47-425d-92af-584f01f5d8b5"
   },
   "outputs": [],
   "source": [
    "tokenizer.tokenize(\"I can't wait to visit Bulgaria again!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2705,
     "status": "ok",
     "timestamp": 1611752265508,
     "user": {
      "displayName": "Akash Das",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjOjhArzumpHzN1_p3oinNftWxwSl7K3ieh0roeTiY=s64",
      "userId": "00521560618217958862"
     },
     "user_tz": -330
    },
    "id": "OqP6IDD_jTPW",
    "outputId": "b10f8255-080d-4b8f-def5-30977009acb6"
   },
   "outputs": [],
   "source": [
    "classes = train.labels.unique().tolist()\n",
    " \n",
    "data = IntentDetectionData(train, test, tokenizer, classes, max_seq_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XY7--ESMlzLx"
   },
   "outputs": [],
   "source": [
    "responses=pd.read_csv(main_path+'response.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oIFYksNZweZQ"
   },
   "outputs": [],
   "source": [
    "# import our chat-bot intents file\n",
    "import json\n",
    "with open(main_path+'intents.json') as json_data:\n",
    "    intents = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lptp6SQbsk4v"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "# create a data structure to hold user context\n",
    "context = {}\n",
    " \n",
    " \n",
    "ERROR_THRESHOLD = 0.25\n",
    "def classify(sentence):\n",
    "    sentence=[sentence]\n",
    "    pred_tokens = map(tokenizer.tokenize, sentence)\n",
    "    pred_tokens = map(lambda tok: [\"[CLS]\"] + tok + [\"[SEP]\"], pred_tokens)\n",
    "    pred_token_ids = list(map(tokenizer.convert_tokens_to_ids, pred_tokens))\n",
    " \n",
    "    pred_token_ids = map(lambda tids: tids +[0]*(data.max_seq_len-len(tids)),pred_token_ids)\n",
    "    pred_token_ids = np.array(list(pred_token_ids))\n",
    " \n",
    "    predictions = model.predict(pred_token_ids)\n",
    "    predictions1=np.argmax(model.predict(pred_token_ids))\n",
    "    \n",
    "    return_list =[]\n",
    "    return_list.append((classes[predictions1],np.amax(predictions[0])))\n",
    "    \n",
    "    return return_list\n",
    " \n",
    " \n",
    "def response(sentence, userID='123', show_details=False):\n",
    "    results = classify(sentence)\n",
    "    # if we have a classification then find the matching intent tag\n",
    "    if results:\n",
    "        # loop as long as there are matches to process\n",
    "        while results:\n",
    "            for i in intents['intents']:\n",
    "                # find a tag matching the first result\n",
    "                if i['tag'] == results[0][0]:\n",
    "                    x=i['id']\n",
    "                    # set context for this intent if necessary\n",
    "                    if 'context_set' in i:\n",
    "                        if show_details: \n",
    "                            return (('context:', i['context_set']),x)\n",
    "                        context[userID] = i['context_set']\n",
    " \n",
    "                    # check if this intent is contextual and applies to this user's conversation\n",
    "                    if not 'context_filter' in i or \\\n",
    "                        (userID in context and 'context_filter' in i and i['context_filter'] == context[userID]):\n",
    "                        if show_details: print ('tag:', i['tag'])\n",
    "                        # a random response from the intent\n",
    "                        return (random.choice(i['responses']),x)\n",
    "    \n",
    "            results.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4664,
     "status": "ok",
     "timestamp": 1611752304804,
     "user": {
      "displayName": "Akash Das",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjOjhArzumpHzN1_p3oinNftWxwSl7K3ieh0roeTiY=s64",
      "userId": "00521560618217958862"
     },
     "user_tz": -330
    },
    "id": "jwZTeld8s5To",
    "outputId": "00ab0a65-d560-44b8-c398-72e81f7edc08"
   },
   "outputs": [],
   "source": [
    "sent=\"electronics\"\n",
    "print(classify(sent),response(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence='hi'\n",
    "results = classify(sentence)\n",
    "print(results)\n",
    "show_details=False\n",
    "userID='123'\n",
    "    # if we have a classification then find the matching intent tag\n",
    "if results:\n",
    "        # loop as long as there are matches to process\n",
    "            for i in intents['intents']:\n",
    "                # find a tag matching the first result\n",
    "                if i['tag'] == results[0][0]:\n",
    "                    x=i['id']\n",
    "                    # set context for this intent if necessary\n",
    "                    if 'context_set' in i:\n",
    "                        if show_details: \n",
    "                            print (('context:', i['context_set']),x)\n",
    "                        context[userID] = i['context_set']\n",
    " \n",
    "                    # check if this intent is contextual and applies to this user's conversation\n",
    "                    if not 'context_filter' in i or \\\n",
    "                        (userID in context and 'context_filter' in i and i['context_filter'] == context[userID]):\n",
    "                        if show_details: print ('tag:', i['tag'])\n",
    "                        # a random response from the intent\n",
    "                        print (random.choice(i['responses']),x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EE2paiTZ3nb3",
    "outputId": "a270adab-a04f-4828-ee6b-73b954f5a1d2"
   },
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, jsonify\n",
    "#from flask_ngrok import run_with_ngrok\n",
    "app = Flask(__name__, template_folder=main_path+'templates/UI')\n",
    "#run_with_ngrok(app)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "\treturn render_template('index2.html')\n",
    "\n",
    "@app.route('/get')\n",
    "def get_bot_response():\n",
    "\tmessage = request.args.get('msg')\n",
    "\tif message:\n",
    "\t\tmessage = message.lower()\n",
    "\t\tres,x=response(message)\n",
    "        #x=str(x)\n",
    "\t\treturn (str(x)+\" \"+str(res))\n",
    "\treturn \"Missing Data!\"\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tapp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4487,
     "status": "ok",
     "timestamp": 1611571583556,
     "user": {
      "displayName": "Akash Das",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjOjhArzumpHzN1_p3oinNftWxwSl7K3ieh0roeTiY=s64",
      "userId": "00521560618217958862"
     },
     "user_tz": -330
    },
    "id": "BBBAI0mRig5H",
    "outputId": "fded6abb-6e08-42b2-9639-7a0f094bd189"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "sentences = [\n",
    "  \"heya\",\n",
    "  \"Intake Capacity\"\n",
    "]\n",
    "\n",
    "pred_tokens = map(tokenizer.tokenize, sentences)\n",
    "pred_tokens = map(lambda tok: [\"[CLS]\"] + tok + [\"[SEP]\"], pred_tokens)\n",
    "pred_token_ids = list(map(tokenizer.convert_tokens_to_ids, pred_tokens))\n",
    "\n",
    "pred_token_ids = map(lambda tids: tids +[0]*(data.max_seq_len-len(tids)),pred_token_ids)\n",
    "pred_token_ids = np.array(list(pred_token_ids))\n",
    "\n",
    "predictions = model.predict(pred_token_ids).argmax(axis=-1)\n",
    "#print(predictions)\n",
    "#print(classes)\n",
    "for text, label in zip(sentences, predictions):\n",
    "  print(\"text:\", text, \"\\nintent:\", classes[label])\n",
    "  print()\n",
    "  c=0\n",
    "  for i in range(len(classes)):\n",
    "    if responses['labels'][i]==classes[label]:\n",
    "      #x=responses.groupby('labels').get_group(i).responses\n",
    "      # r = np.random.randint(0,x)\n",
    "      resp = responses['responses'][c]\n",
    "      print(resp)\n",
    "    c=c+1\n",
    "  print()\n",
    "\n",
    "sentence=['hi']\n",
    "def give_response(sentence):\n",
    "    pred_tokens = map(tokenizer.tokenize, sentence)\n",
    "    pred_tokens = map(lambda tok: [\"[CLS]\"] + tok + [\"[SEP]\"], pred_tokens)\n",
    "    pred_token_ids = list(map(tokenizer.convert_tokens_to_ids, pred_tokens))\n",
    "\n",
    "    pred_token_ids = map(lambda tids: tids +[0]*(data.max_seq_len-len(tids)),pred_token_ids)  \n",
    "    pred_token_ids = np.array(list(pred_token_ids))\n",
    "\n",
    "    predictions = model.predict(pred_token_ids).argmax(axis=-1)\n",
    "    print(predictions)\n",
    "    print()\n",
    "    print(\"\\nintent:\", classes[predictions[0]])\n",
    "    print('response:',responses['responses'][predictions[0]])\n",
    "\n",
    "give_response(sentence)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOEbOB9guBy0v7uPsykyBot",
   "collapsed_sections": [],
   "name": "Copy of Implement.ipynb",
   "provenance": [
    {
     "file_id": "1KLpXslUuTwj_2J3ofQbJD8ZPeCB3B24n",
     "timestamp": 1611832601184
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
